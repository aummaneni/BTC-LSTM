# -*- coding: utf-8 -*-
"""LSTM_testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BcWQk_pEiKzi98YBBpFeQBsT_iEkaUhX
"""

!pip install requests
!pip install pandas_ta
!pip install keras
!pip install keras-tuner


import requests
import time
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Model
from keras.layers import Dense, Dropout, LSTM, Input, BatchNormalization
from keras import optimizers
import pandas_ta as ta
from keras_tuner import RandomSearch
from keras.layers import Layer
import keras.backend as K
from sklearn.model_selection import KFold
from keras.callbacks import EarlyStopping

# CryptoCompare API key
api_key = '52c972a27d45c04b20c41340e0ee2d68b4b8a88b3c1dfa1675eab62fa90965b2'

# Function definitions remain the same
# (fetch_current_price, fetch_current_trading_info, fetch_historical_crypto_data, add_indicators)
def fetch_current_price(fsym, tsym):
    url = f'https://min-api.cryptocompare.com/data/price?fsym={fsym}&tsyms={tsym}&api_key={api_key}'
    response = requests.get(url).json()
    return response[tsym]

# Function to fetch current trading information for a list of cryptocurrencies
def fetch_current_trading_info(fsyms, tsyms):
    url = f'https://min-api.cryptocompare.com/data/pricemultifull?fsyms={fsyms}&tsyms={tsyms}&api_key={api_key}'
    response = requests.get(url).json()
    return response['RAW']

# Function to fetch intraday data from CryptoCompare until an error is received
def fetch_historical_crypto_data(fsym, tsym, limit=2000):
    end_time = int(time.time())
    data_frames = []

    while True:
        url = f'https://min-api.cryptocompare.com/data/v2/histominute?fsym={fsym}&tsym={tsym}&limit={limit}&toTs={end_time}&api_key={api_key}'
        'https://min-api.cryptocompare.com/data/v2/histohour?fsym=BTC&tsym=USD&limit=10'
        r = requests.get(url)
        response = r.json()

        if response.get('Response') == 'Error':
            print(f"Error received: {response.get('Message')}")
            break

        data = response['Data']['Data']
        df = pd.DataFrame(data)
        data_frames.append(df)
        end_time = df['time'].min()  # Update end_time to the earliest timestamp from the fetched data

        # Check if we have enough data
        if len(pd.concat(data_frames)) >= 7 * 24 * 60:  # One week of minute data
            break

    full_data = pd.concat(data_frames).drop_duplicates(subset=['time'])
    full_data['time'] = pd.to_datetime(full_data['time'], unit='s')
    full_data.set_index('time', inplace=True)
    return full_data

# Adding technical indicators to the data
def add_indicators(data):
    data['RSI'] = ta.rsi(data['close'], length=15)
    data['EMA9'] = ta.ema(data['close'], length=9)
    data['EMA21'] = ta.ema(data['close'], length=21)
    data['MOM'] = ta.mom(data['close'], length=10)  # Momentum
    data['EMA9_slope'] = data['EMA9'].diff()
    data['EMA21_slope'] = data['EMA21'].diff()

    bb = ta.bbands(data['close'], length=20)
    if bb is not None and not bb.empty:
        data['BB_upper'], data['BB_middle'], data['BB_lower'] = bb.iloc[:, 0], bb.iloc[:, 1], bb.iloc[:, 2]

    macd = ta.macd(data['close'])
    if macd is not None and not macd.empty:
        data['MACD'], data['MACD_signal'], data['MACD_hist'] = macd.iloc[:, 0], macd.iloc[:, 1], macd.iloc[:, 2]

    data['Target'] = data['close'] - data['open']
    data['Target'] = data['Target'].shift(-1)
    data['TargetClass'] = [1 if data.Target[i] > 0 else 0 for i in range(len(data))]
    data['TargetNextClose'] = data['close'].shift(-1)
    print(data.shape)
    # Instead of dropping all rows with any NaN values, drop rows where the key columns are NaN
    data = data.dropna(subset=['RSI', 'EMA9', 'EMA21', 'MOM', 'EMA9_slope', 'EMA21_slope', 'BB_upper', 'BB_middle', 'BB_lower', 'MACD', 'MACD_signal', 'MACD_hist', 'Target', 'TargetClass', 'TargetNextClose'])
    print(data.shape)
    print(data.columns)
    return data

# Initial fetching of Bitcoin data (1-minute interval)
train_data = fetch_historical_crypto_data('BTC', 'USD')
train_data = add_indicators(train_data)

# Exclude non-numeric columns for scaling
numeric_cols = train_data.select_dtypes(include=[np.number]).columns

# Preparing training data for LSTM
backcandles = 50
X_train = []

for j in range(train_data[numeric_cols].shape[1] - 2):  # Exclude Target and TargetClass
    X_train.append([])
    for i in range(backcandles, train_data.shape[0]):
        X_train[j].append(train_data.iloc[i-backcandles:i][numeric_cols[j]].values)

X_train = np.moveaxis(X_train, [0], [2])
y_train = np.array(train_data['Target'].values[backcandles:]).reshape(-1, 1)

# Scaling the training data
sc = MinMaxScaler(feature_range=(0, 1))
X_train_scaled = sc.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)

# Scaling the target variable in training data
sc_y = MinMaxScaler(feature_range=(0, 1))
y_train_scaled = sc_y.fit_transform(y_train)

# Attention Layer
class Attention(Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], input_shape[-1]), initializer='random_normal', trainable=True)
        self.b = self.add_weight(name='attention_bias', shape=(input_shape[-1],), initializer='zeros', trainable=True)
        super(Attention, self).build(input_shape)

    def call(self, x):
        e = K.tanh(K.dot(x, self.W) + self.b)
        a = K.softmax(e, axis=1)
        output = K.batch_dot(a, x, axes=[1, 1])
        return output

# Building a model with attention mechanism for hyperparameter tuning
def build_model(hp):
    lstm_input = Input(shape=(backcandles, X_train_scaled.shape[2]), name='lstm_input')

    # Tune the number of units and activation type in the LSTM layers

    x = LSTM(units=hp.Int('units_1', min_value=50, max_value=200, step=50), return_sequences=True, activation='tanh')(lstm_input)
    x = Dropout(0.15)(x)
    #x = BatchNormalization()(x)

    x = LSTM(units=hp.Int('units_2', min_value=50, max_value=200, step=50), return_sequences=True, activation='tanh')(x)
    x = Dropout(0.2)(x)
    #x = BatchNormalization()(x)

    x = Attention()(x)  # Adding Attention layer
    x = Dense(hp.Int('dense_units', min_value=16, max_value=64, step=16), activation='relu')(x)
    #x = BatchNormalization()(x)

    output = Dense(1, activation='tanh', name='output')(x)
    model = Model(inputs=lstm_input, outputs=output)

    model.compile(optimizer=optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])), loss='mse')
    return model

def tune_and_evaluate_model(X, y, n_splits=5):
    kfold = KFold(n_splits=n_splits, shuffle=True)
    all_scores = []
    best_tuner = None

    for train_index, val_index in kfold.split(X):
        X_train_fold, X_val_fold = X[train_index], X[val_index]
        y_train_fold, y_val_fold = y[train_index], y[val_index]

        tuner = RandomSearch(
            build_model,
            objective='val_loss',
            max_trials=10,
            executions_per_trial=1,
            directory='tuner_dir',
            project_name='lstm_hyperparameter_tuning'
        )

        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

        tuner.search(X_train_fold, y_train_fold, epochs=72, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping])
        best_model = tuner.get_best_models(num_models=1)[0]

        # Evaluate the best model on the validation fold
        val_loss = best_model.evaluate(X_val_fold, y_val_fold)
        all_scores.append(val_loss)
        best_tuner = tuner

    return all_scores, best_tuner

# Run the tuner with k-fold cross-validation
scores, tuner = tune_and_evaluate_model(X_train_scaled, y_train_scaled)
print(f"Validation scores from k-fold cross-validation: {scores}")
print(f"Mean validation score: {np.mean(scores)}")

# Final training on all data
best_model = tuner.get_best_models(num_models=1)[0]
best_model.fit(X_train_scaled, y_train_scaled, epochs=72, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)])
import time
import pandas as pd
import numpy as np

# Initialize variables for live prediction accuracy tracking
correct_predictions = 0
total_predictions = 0
update_interval = 60  # Update interval in seconds
duration = 2 * 60 * 60  # Run simulation for 2 hours
end_time = time.time() + duration

# DataFrame to store the metrics
metrics_df = pd.DataFrame(columns=['Time', 'Current Price', 'Predicted Price', 'Actual Price', 'Percent Difference'])

# Live prediction accuracy and price comparison loop
while time.time() < end_time:
    try:
        # Fetch and show the current BTC price
        trading_info = fetch_current_trading_info('BTC', 'USD')
        current_info = trading_info['BTC']['USD']
        current_price = current_info['PRICE']
        print(f"Current BTC price: ${current_price:.2f}")

        # Preparing test data for LSTM
        if train_data.shape[0] >= backcandles:
            X_test = []
            for j in range(train_data[numeric_cols].shape[1] - 2):  # Exclude Target and TargetClass
                X_test.append([])
                for i in range(backcandles, train_data.shape[0]):
                    X_test[j].append(train_data.iloc[i-backcandles:i][numeric_cols[j]].values)

            X_test = np.moveaxis(X_test, [0], [2])
            y_test = np.array(train_data['Target'].values[backcandles:]).reshape(-1, 1)

            if X_test.shape[0] > 0 and y_test.shape[0] > 0:
                # Scaling the test data
                X_test_scaled = sc.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)
                y_test_scaled = sc_y.transform(y_test)

                # Predicting the price change
                y_pred_scaled = best_model.predict(X_test_scaled)

                # Reshape y_pred_scaled to 2D array
                y_pred_scaled_2d = y_pred_scaled.reshape(-1, 1)

                y_pred = sc_y.inverse_transform(y_pred_scaled_2d)

                # Calculate predicted next price
                predicted_price = current_price + y_pred[-1][0]
                print(f"Predicted next price: ${predicted_price:.2f}")

        # Wait for the next minute to get the actual next price
        time.sleep(update_interval)

        # Fetch and show the actual next price
        next_trading_info = fetch_current_trading_info('BTC', 'USD')
        next_current_info = next_trading_info['BTC']['USD']
        actual_next_price = next_current_info['PRICE']
        print(f"Actual next price: ${actual_next_price:.2f}")

        # Create a new row of data with the actual next price
        actual_next_row = pd.DataFrame({
            'time': [pd.to_datetime(time.time(), unit='s')],
            'close': [actual_next_price],
            'open': [next_current_info['OPEN24HOUR']],
            'high': [next_current_info['HIGH24HOUR']],
            'low': [next_current_info['LOW24HOUR']],
            'volumefrom': [0],  # Placeholder, as volume data is not used in the indicators
            'volumeto': [next_current_info['VOLUME24HOUR']]
        })

        # Append the actual next row to the train data
        train_data = pd.concat([train_data, actual_next_row], ignore_index=True)

        # Ensure we have enough historical data points before adding indicators
        if train_data.shape[0] < backcandles:
            print("Not enough historical data to calculate indicators.")
            continue

        train_data = add_indicators(train_data)

        if train_data.empty:
            print("No new data fetched.")
            continue

        # Check prediction accuracy
        if (y_pred[-1][0] > 0 and (actual_next_price - current_price) > 0) or (y_pred[-1][0] < 0 and (actual_next_price - current_price) < 0):
            correct_predictions += 1

        total_predictions += 1
        accuracy = (correct_predictions / total_predictions) * 100
        percent_difference = abs(predicted_price - actual_next_price) / actual_next_price * 100

        print(f"Accuracy so far: {accuracy:.2f}%")

        # Store metrics in DataFrame
        metrics_df = pd.concat([metrics_df, pd.DataFrame({
            'Time': [pd.to_datetime(time.time(), unit='s')],
            'Current Price': [current_price],
            'Predicted Price': [predicted_price],
            'Actual Price': [actual_next_price],
            'Percent Difference': [percent_difference]
        })], ignore_index=True)

    except KeyboardInterrupt:
        print("Live prediction accuracy tracking stopped.")
        print(f"Final accuracy: {accuracy:.2f}%")
        break
# Output metrics to Excel
metrics_df.to_excel('prediction_metrics.xlsx', index=False)
print("Metrics saved to prediction_metrics.xlsx")